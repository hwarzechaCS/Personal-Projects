{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as func\n",
    "from torch.nn import Linear as lin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from torch.distributions.multinomial import Multinomial\n",
    "from transformers import BertForTokenClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import BertTokenizer\n",
    "from transformers import DistilBertForTokenClassification\n",
    "from transformers import BertForMaskedLM\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train_Tagged_Titles.tsv.gz\", sep=\"\\t\", dtype=str, keep_default_na=False, na_values=[\"\"], quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(df)):\n",
    "    if type(df[\"Tag\"][i]) == float:\n",
    "        df[\"Tag\"][i] = \"Next\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dict = {}\n",
    "with open(\"glove.840B.300d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        vals = line.split(\" \")\n",
    "        vec_dict[vals[0]] = np.asarray(vals[1:], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObj = open('word_dict.obj', 'rb')\n",
    "words = pickle.load(fileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[\"Next\"] = np.zeros((32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2', device=\"cuda\")\n",
    "rows = []\n",
    "duds = {}\n",
    "is_mpn = []\n",
    "for i in set(df[\"Tag\"].values.tolist()):\n",
    "    duds[i] = []\n",
    "nt = []\n",
    "cnt = 0\n",
    "pred_idx = 0\n",
    "for i in range(1,5001):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    listing = df[df[\"Record Number\"] == str(i)]\n",
    "    transformed = []\n",
    "    #preds_next = next_preds[pred_idx:pred_idx + len(listing)]\n",
    "    #pred_idx += len(listing) - 1\n",
    "    \n",
    "    sent_vec = model.encode(listing[\"Title\"].values[0].lower())\n",
    "    first = True\n",
    "    pred_listing = 0\n",
    "    for idx, row in listing.iterrows():\n",
    "        \"\"\"if first:\n",
    "            sig = 0\n",
    "            first = False\n",
    "        else:\n",
    "            sig = preds_next[pred_listing]\n",
    "            pred_listing += 1\"\"\"\n",
    "        try:\n",
    "            tok_vec = vec_dict[row[\"Token\"].lower()]\n",
    "            transformed.append(np.hstack((sent_vec, tok_vec, words[row[\"Tag\"]])))\n",
    "        except:\n",
    "            v = np.zeros((300,))\n",
    "            div = len(row[\"Token\"])\n",
    "            for let in row[\"Token\"]:\n",
    "                if let in vec_dict:\n",
    "                    v = v + vec_dict[let]\n",
    "                else:\n",
    "                    div -= 1\n",
    "            if div != 0:\n",
    "                tok_vec = v/div\n",
    "            else:\n",
    "                tok_vec = vec_dict[\"number\"]\n",
    "                \n",
    "            transformed.append(np.hstack((sent_vec, tok_vec, words[row[\"Tag\"]])))\n",
    "        \n",
    "    rows += transformed\n",
    "vec_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(df):\n",
    "    text = []\n",
    "    labels = []\n",
    "    for i in range(1,5001):\n",
    "        listing = df[df[\"Record Number\"] == str(i)]\n",
    "        \n",
    "        text.append(listing[\"Token\"].values.tolist())\n",
    "        labels.append(listing[\"Tag\"].values.tolist())\n",
    "    return text, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_to_id = {}\n",
    "cnt = 0\n",
    "for i in set(df[\"Tag\"].values.tolist()):\n",
    "    \n",
    "    tag_to_id[i] = cnt\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_tag = {}\n",
    "cnt = 0\n",
    "for i in set(df[\"Tag\"].values.tolist()):\n",
    "    id_to_tag[cnt] = i\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, labels = get_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "all_encodings = tokenizer(text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"nickprock/bert-finetuned-ner-ontonotes\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"batterydata/bde-pos-bert-cased-base\")\n",
    "\n",
    "all_encodings = tokenizer(text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tags(tags, encodings):\n",
    "    labels = []\n",
    "    for doc in tags:\n",
    "        f = []\n",
    "        for tag in doc:\n",
    "            f.append(tag_to_id[tag])\n",
    "        labels.append(f)\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "        d = doc_offset\n",
    "        for i in range(40 - len(d)):\n",
    "            d.append((0,0))\n",
    "        doc_enc_labels = np.ones(40,dtype=int) * -100\n",
    "        arr_offset = np.array(d)\n",
    "        # set labels whose first offset position is 0 and the second is not 0\n",
    "        doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = np.array(doc_labels)\n",
    "        \"\"\"last = 0\n",
    "        c = arr_offset[:,1].flatten()\n",
    "        for v in range(1, len(c)):\n",
    "            if c[v] == 0:\n",
    "                for lab in range(1, v+1):\n",
    "                    if doc_enc_labels[lab] != -100:\n",
    "                        last = doc_enc_labels[lab]\n",
    "                    if doc_enc_labels[lab] == -100:\n",
    "                        doc_enc_labels[lab] = last\n",
    "                break\n",
    "            \"\"\"\n",
    "\n",
    "        encoded_labels.append(doc_enc_labels.tolist())\n",
    "    \n",
    "\n",
    "    return encoded_labels\n",
    "\n",
    "train_tags = encode_tags(labels, all_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "500\n",
      "750\n",
      "1000\n",
      "1250\n",
      "1500\n",
      "1750\n",
      "2000\n",
      "2250\n",
      "2500\n",
      "2750\n",
      "3000\n",
      "3250\n",
      "3500\n",
      "3750\n",
      "4000\n",
      "4250\n",
      "4500\n",
      "4750\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "#bert = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "#bert = AutoModelForTokenClassification.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
    "#bert = AutoModelForTokenClassification.from_pretrained(\"nickprock/bert-finetuned-ner-ontonotes\")\n",
    "bert = AutoModelForTokenClassification.from_pretrained(\"batterydata/bde-pos-bert-cased-base\")\n",
    "#bert.load_state_dict(torch.load(\"cl_params.obj\"))\n",
    "#bert_8 = deleteEncodingLayers(bert, 10)\n",
    "#bert_8.eval()\n",
    "bert.eval() \n",
    "r = []\n",
    "r_8 = []\n",
    "for i in range(250,5001,250):\n",
    "    print(i)\n",
    "    #r_8 += bert_8.bert(input_ids=torch.tensor(all_encodings[\"input_ids\"][i-250:i]).cpu(), attention_mask=torch.tensor(all_encodings[\"attention_mask\"][i-250:i]).cpu())[0].cpu().tolist()\n",
    "    r+= bert.bert(input_ids=torch.tensor(all_encodings[\"input_ids\"][i-250:i]).cpu(), attention_mask=torch.tensor(all_encodings[\"attention_mask\"][i-250:i]).cpu())[0].cpu().tolist()\n",
    "r = torch.tensor(r)\n",
    "#r_8 = torch.tensor(r_8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "offset = all_encodings.offset_mapping\n",
    "for i in range(len(offset)):\n",
    "    \n",
    "    row = []\n",
    "    first = True\n",
    "    forward = 1\n",
    "    accm = None\n",
    "    first_full_zero = True\n",
    "    for j in range(1, len(offset[i])):\n",
    "        if offset[i][j][0] == 0 and offset[i][j][1] != 0:\n",
    "            if first:\n",
    "                accm = r[i][j]\n",
    "                first = False\n",
    "            else:\n",
    "                accm = accm/forward\n",
    "                row.append(accm.tolist())\n",
    "                accm = r[i][j]\n",
    "                is_same = True\n",
    "                forward = 1\n",
    "        elif offset[i][j][0] != 0:\n",
    "            accm += r[i][j]\n",
    "            forward += 1\n",
    "        if offset[i][j][0] == 0 and offset[i][j][1] == 0 and first_full_zero:\n",
    "            accm = accm/forward\n",
    "            row.append(accm.tolist())\n",
    "            first_full_zero = False\n",
    "    out += row\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_train = np.hstack((np.array(out), np.array(rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_train = np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_bert = np.load(\"ft_next_bert.npy\")\n",
    "reg_train = np.hstack((reg_train, ft_bert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ft_next_bert.npy\", reg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_out = np.load(\"ft_next_bert.npy\")\n",
    "bert_out = bert_out.astype(np.float16)[:,:-32]\n",
    "bert_out = np.hstack(bert_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PCA(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_out = np.hstack((bert_out[:,:768*2], bert_out[:,768*3:768*4], bert_out[:,768*5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data = []\n",
    "count = 0\n",
    "for m in range(5000):\n",
    "    listing = labels[m]\n",
    "    bert_listing = bert_out[count:count + len(listing), :]\n",
    "    bert_listing = np.hstack((bert_listing[:len(bert_listing)-1, :], bert_listing[1:,:]))\n",
    "    is_next = []\n",
    "    for j in range(1, len(listing)):\n",
    "        prev = listing[j]\n",
    "        if prev == \"Next\":\n",
    "            is_next.append(1)\n",
    "        else:\n",
    "            is_next.append(0)\n",
    "    count += len(listing)\n",
    "    bert_data += np.hstack((bert_listing, np.array(is_next).reshape(len(is_next), 1))).tolist()\n",
    "bert_data = np.array(bert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"temp_f.npy\", bert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_full = np.vstack((np.load(\"temp_f.npy\"), bert_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"bert_next.npy\", bert_data.astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = np.load(\"ft_bert.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data = np.load(\"bert_next.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8281"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "bert_data = np.hstack((s.fit_transform(bert_data[:,:-1]), bert_data[:,-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96786087,  0.21142467, -0.62581467, ...,  0.02959734,\n",
       "       -0.08240738, -0.01025654])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('next_scalar.obj', 'wb') \n",
    "pickle.dump(s, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "reg = RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifier</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(bert_data[:,:-1], bert_data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"next_feature_idx.npy\",np.where(np.abs(reg.coef_).mean(axis=0) > 0.02)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"next_feature_pca_idx.npy\",np.where(np.abs(reg.coef_).mean(axis=0) < 0.02)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f16742dd2a0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(reg.coef_[0])), np.abs(reg.coef_).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(np.abs(reg.coef_).mean(axis=0) > 0.02)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "p = PCA(n_components=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data = np.hstack((bert_data.T[np.where(np.abs(reg.coef_).mean(axis=0) > 0.02)].T, s.fit_transform(p.fit_transform(bert_data.T[np.where(np.abs(reg.coef_).mean(axis=0) < 0.02)].T)), bert_data[:, -1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1967"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('thresh_next_scalar.obj', 'wb') \n",
    "pickle.dump(s, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('thresh_next_pca.obj', 'wb') \n",
    "pickle.dump(p, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"reg_next.npy\", bert_data.astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_func(y_true, y_pred):\n",
    "    return f1_score(y_pred, y_true, average=\"weighted\", zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data = np.load(\"reg_next.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in, test_in = train_test_split(bert_data, train_size=0.8, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bst = XGBClassifier(n_estimators=3200, min_child_weight=1, learning_rate=0.1, eval_metric=\"error\", max_depth=5,tree_method=\"gpu_hist\", objective='binary:logitraw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;error&#x27;, feature_types=None, gamma=0, gpu_id=0,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=3200, n_jobs=0,\n",
       "              num_parallel_tree=1, objective=&#x27;binary:logitraw&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;error&#x27;, feature_types=None, gamma=0, gpu_id=0,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=3200, n_jobs=0,\n",
       "              num_parallel_tree=1, objective=&#x27;binary:logitraw&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='error', feature_types=None, gamma=0, gpu_id=0,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=5, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=3200, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='binary:logitraw',\n",
       "              predictor='auto', ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.fit(bert_data[:,:-1], bert_data[:,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(bst.predict(test_in[:,:-1]), test_in[:,-1:]))\n",
    "print(accuracy_score(bst.predict(train_in[:,:-1]), train_in[:,-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('bst_next_params.obj', 'wb') \n",
    "pickle.dump(bst, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_next(model, sample_weights=np.array([]), learning_rate=0.0001, l1=0.00001, batch_size=250, max_iter=3000, sample_func=1/2, nxt=None, not_next=None, test=None):\n",
    "    test_s = test\n",
    "    loss_fn = torch.nn.BCELoss(reduction=\"mean\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    current_min = 999999999\n",
    "    num_since = 0\n",
    "\n",
    "    best_params = model.parameters()\n",
    "    max_val_f1 = 0\n",
    "    max_train_f1 = 0\n",
    "    for t in range(200000):\n",
    "        perm_not = torch.randperm(len(not_next))\n",
    "        perm_next = torch.randperm(len(nxt))\n",
    "        nexts = nxt[perm_next][:100]\n",
    "        not_nexts = not_next[perm_not][:100]\n",
    "        x_full = torch.vstack((nexts, not_nexts))\n",
    "        x_train = x_full[:,:-1].cuda()\n",
    "        y_train = x_full[:,-1].cuda()\n",
    "        y_pred = model(x_train)\n",
    "        loss = loss_fn(y_pred.flatten(), y_train)\n",
    "        for i in model.parameters():\n",
    "            loss += (torch.square(i).sum())*l1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step(lambda: loss)\n",
    "        if t%200 == 0:\n",
    "            temp_test = test_s[:,-1].flatten()\n",
    "            temp_train = train_s[:,-1].flatten()\n",
    "            t1 = test_s[:,:-1]\n",
    "            t2 = train_s[:,:-1]\n",
    "            test_out = model(t1).flatten()\n",
    "            train_out = model(t2).flatten()\n",
    "            val_score = 0\n",
    "            train_score = 0\n",
    "            for n in range(len(test_out)):\n",
    "                if test_out[n] >= 0.5 and temp_test[n] == 1:\n",
    "                    val_score += 1\n",
    "                elif test_out[n] <= 0.5 and temp_test[n] == 0:\n",
    "                    val_score += 1\n",
    "            for n in range(len(train_out)):\n",
    "                if train_out[n] >= 0.5 and temp_train[n] == 1:\n",
    "                    train_score += 1\n",
    "                elif train_out[n] <= 0.5 and temp_train[n] == 0:\n",
    "                    train_score += 1\n",
    "                \n",
    "            print(t, loss)\n",
    "            print(\"train f1: \", train_score/len(train_out))\n",
    "            print(\"val f1: \",val_score/len(test_out))\n",
    "            if val_score > max_val_f1:\n",
    "                max_val_f1 = val_score\n",
    "                best_params = model.parameters()\n",
    "            if train_score > max_train_f1:\n",
    "                max_train_f1 = val_score\n",
    "                best_params = model.parameters()\n",
    "        if loss.item() < current_min:\n",
    "            num_since = 0\n",
    "            current_min = loss\n",
    "            \n",
    "        elif num_since >= max_iter:\n",
    "            print(\"max iter\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            num_since += 1\n",
    "    \n",
    "    return (val_score, train_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_next(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(len(train_s[0])-1, 128).cuda()\n",
    "        self.l5 = nn.Linear(128, 1).cuda()\n",
    "        self.layers = [self.l1, self.l5]\n",
    "    def forward(self, x):\n",
    "        #d = nn.Dropout(p=0.5)\n",
    "        x = self.l1(x)\n",
    "        x = func.silu(x)\n",
    "        #x = d(x)\n",
    "        #x = self.l2(x)\n",
    "        #x = func.silu(x)\n",
    "        #x = d(x)\n",
    "        x = self.l5(x)\n",
    "        return torch.sigmoid(x)\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for p in self.layers:\n",
    "            params.append(p.weight)\n",
    "            params.append(p.bias)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert_data = np.hstack((bert_out, np.array(y).reshape(len(y), 1)))\n",
    "s = StandardScaler()\n",
    "train_next_bert = s.fit_transform(bert_data[:,:-1])\n",
    "train_next_bert = np.hstack((train_next_bert, bert_data[:,-1].reshape(len(bert_data[:,-1]),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.array(rows)\n",
    "s = StandardScaler()\n",
    "train_next = s.fit_transform(rows[:,:-1])\n",
    "train_next = np.hstack((train_next,rows[:,-1].reshape(len(rows[:,-1]),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PCA(n_components=10)\n",
    "t = p.fit_transform(train_next[:,300:-1])\n",
    "t2 = p.fit_transform(train_next[:,:300])\n",
    "train_next = np.hstack((t,t2, train_next[:,-1].reshape(len(rows[:,-1]),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PCA(n_components=20)\n",
    "t = p.fit_transform(train_next_bert[:,768:-1])\n",
    "t2 = p.fit_transform(train_next_bert[:,:768])\n",
    "train_next_bert = np.hstack((t, t2, train_next_bert[:,-1].reshape(len(train_next_bert), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexts = train_next[np.where(rows[:,-1] == 1)]\n",
    "not_nexts = train_next[np.where(rows[:,-1] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexts_bert = train_next_bert[np.where(train_next_bert[:,-1] == 1)]\n",
    "not_nexts_bert = train_next_bert[np.where(train_next_bert[:,-1] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexts = np.hstack((nexts_bert[:,:-1], nexts))\n",
    "not_nexts = np.hstack((not_nexts_bert[:,:-1], not_nexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_next = np.vstack((nexts, not_nexts[:10000,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s, test_s = train_test_split(train_pca, train_size=0.9)\n",
    "train_s = torch.tensor(train_s).cuda().float()\n",
    "test_s = torch.tensor(test_s).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_next = np.hstack((train_next_bert[:,:-1], train_next))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s, test_s = train_test_split(bert_data, train_size=0.9)\n",
    "train_s = torch.tensor(train_s).cuda().float()\n",
    "test_s = torch.tensor(test_s).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexts_in = train_s[torch.where(train_s[:,-1] == 1)]\n",
    "not_nexts_in = train_s[torch.where(train_s[:,-1] == 0)]\n",
    "#nexts_in = nexts_in\n",
    "#not_nexts_in = not_nexts_in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_mdl = Model_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.7200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.4295246962844728\n",
      "val f1:  0.4250947536405346\n",
      "200 tensor(0.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.7209364192604416\n",
      "val f1:  0.7267105525633353\n",
      "400 tensor(0.4407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.8348408264609382\n",
      "val f1:  0.8424097346898065\n",
      "600 tensor(0.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.8721512813691584\n",
      "val f1:  0.8759226012367843\n",
      "800 tensor(0.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.8847876208211404\n",
      "val f1:  0.8874925194494315\n",
      "1000 tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.8934557063048684\n",
      "val f1:  0.8920805904647915\n",
      "1200 tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.8985767491354083\n",
      "val f1:  0.8974665868741273\n",
      "1400 tensor(0.2787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9015473973574533\n",
      "val f1:  0.8988629563135847\n",
      "1600 tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9080207501995211\n",
      "val f1:  0.9032515459804509\n",
      "1800 tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.911722975968786\n",
      "val f1:  0.9070416916018352\n",
      "2000 tensor(0.2573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9144719340250067\n",
      "val f1:  0.9094354677837622\n",
      "2200 tensor(0.2992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9197703289882061\n",
      "val f1:  0.9124276880111709\n",
      "2400 tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9216325263811297\n",
      "val f1:  0.9118292439656892\n",
      "2600 tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9250243859182407\n",
      "val f1:  0.9154199082385797\n",
      "2800 tensor(0.2257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9264210339629334\n",
      "val f1:  0.914621982844604\n",
      "3000 tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9290591469362419\n",
      "val f1:  0.9156193895870736\n",
      "3200 tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9323844994236056\n",
      "val f1:  0.9192100538599641\n",
      "3400 tensor(0.2056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9337811474682983\n",
      "val f1:  0.9180131657690006\n",
      "3600 tensor(0.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9359758801099584\n",
      "val f1:  0.9184121284659884\n",
      "3800 tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9386361620998492\n",
      "val f1:  0.9192100538599641\n",
      "4000 tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9404540214596081\n",
      "val f1:  0.9226012367843607\n",
      "4200 tensor(0.1713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9412964440897402\n",
      "val f1:  0.9222022740873729\n",
      "4400 tensor(0.2006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9436685288640596\n",
      "val f1:  0.9233991621783363\n",
      "4600 tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9461514587212911\n",
      "val f1:  0.9245960502692998\n",
      "4800 tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9495433182584021\n",
      "val f1:  0.9281867145421903\n",
      "5000 tensor(0.1872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.949277290059413\n",
      "val f1:  0.9273887891482147\n",
      "5200 tensor(0.1502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9501640507227099\n",
      "val f1:  0.9259924197087572\n",
      "5400 tensor(0.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9532012059945021\n",
      "val f1:  0.9297825653301416\n",
      "5600 tensor(0.1658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9536002482929857\n",
      "val f1:  0.9279872331936964\n",
      "5800 tensor(0.1262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9547308681386893\n",
      "val f1:  0.9287851585876721\n",
      "6000 tensor(0.1401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9536002482929857\n",
      "val f1:  0.9281867145421903\n",
      "6200 tensor(0.1603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9580783896426355\n",
      "val f1:  0.9295830839816477\n",
      "6400 tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9576128402944045\n",
      "val f1:  0.9309794534211051\n",
      "6600 tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9600514321184712\n",
      "val f1:  0.9319768601635747\n",
      "6800 tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9591868404717566\n",
      "val f1:  0.9325753042090564\n",
      "7000 tensor(0.1733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9617584463953179\n",
      "val f1:  0.9341711549970078\n",
      "7200 tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9632659395229227\n",
      "val f1:  0.9347695990424896\n",
      "7400 tensor(0.1548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9653719960982531\n",
      "val f1:  0.9365649311789348\n",
      "7600 tensor(0.1373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9639753480535603\n",
      "val f1:  0.9353680430879713\n",
      "7800 tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9641305311696373\n",
      "val f1:  0.9343706363455017\n",
      "8000 tensor(0.1218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9663030947947149\n",
      "val f1:  0.9363654498304409\n",
      "8200 tensor(0.1183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9669459962756052\n",
      "val f1:  0.9363654498304409\n",
      "8400 tensor(0.1564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9692959120333422\n",
      "val f1:  0.9393576700578495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_28419/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">83539577.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_28419/83539577.py'</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_28419/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">561252675.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">56</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_loop_next</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_28419/561252675.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_28419/\u001b[0m\u001b[1;33m83539577.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_28419/83539577.py'\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_28419/\u001b[0m\u001b[1;33m561252675.py\u001b[0m:\u001b[94m56\u001b[0m in \u001b[92mtrain_loop_next\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_28419/561252675.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loop_next(next_mdl, learning_rate=0.00001, l1=0.001, batch_size=250, max_iter=5000, nxt=train_s[torch.where(train_s[:,-1] == 1)], not_next=train_s[torch.where(train_s[:,-1] == 0)], test=test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-11-15 21:05:59.414239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-15 21:05:59.414715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-15 21:05:59.414846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as func\n",
    "from torch.nn import Linear as lin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from torch.distributions.multinomial import Multinomial\n",
    "from transformers import BertForTokenClassification\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import BertTokenizer\n",
    "from transformers import DistilBertForTokenClassification\n",
    "from transformers import BertForMaskedLM\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train = np.load(\"transformer_training_array.npy\")\n",
    "attn_mask = np.load(\"transformer_attention_array.npy\")\n",
    "trans_labels = np.load(\"transformer_label_array.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_labels = np.load(\"transformer_label_array.npy\").tolist()\n",
    "for m in range(33):\n",
    "    \n",
    "    out = []\n",
    "    for i in range(len(trans_labels)):\n",
    "        row = []\n",
    "        for j in range(len(trans_labels[i])):\n",
    "            if np.array(trans_labels[i][j]).argmax() == m:\n",
    "                row.append(1)\n",
    "            else:\n",
    "                row.append(0)\n",
    "        out.append(row)\n",
    "    t = np.array(out)\n",
    "    if t.sum() == 6921:\n",
    "        trans_labels = t\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, sample_weights=np.array([]), train_in=None, test_in=None, train_labels=None, test_labels=None, train_attn_mask=None, test_attn_mask=None, learning_rate=0.0001, l1=0.00001, batch_size=250, attention_mask=None, max_iter=3000, sample_func=1/2, data=None, labels=None):\n",
    "    \n",
    "    \n",
    "\n",
    "    loss_fn = torch.nn.BCELoss(reduction=\"mean\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    current_min = 999999999\n",
    "    num_since = 0\n",
    "    best_params = model.parameters()\n",
    "    max_val_f1 = 0\n",
    "    max_train_f1 = 0\n",
    "    train_perm = perm = torch.randperm(len(train_in))\n",
    "    for t in range(200000):\n",
    "        #x_full = weighted_sample(weight, train_s, batch_size)\n",
    "        perm = torch.randperm(len(train_in))\n",
    "        attn_mask_in = train_attn_mask[perm][:batch_size]\n",
    "        train_x_in = train_in[perm][:batch_size]\n",
    "        train_labels_out = train_labels[perm][:batch_size]\n",
    "        train_labels_out = train_labels_out[torch.where(attn_mask_in == False)]\n",
    "        y_pred = model(train_x_in, mask=attn_mask_in)[torch.where(attn_mask_in == False)]\n",
    "        loss = loss_fn(y_pred.flatten(), train_labels_out.flatten())\n",
    "        a = []\n",
    "        for p in model.parameters():\n",
    "            a.append(p)\n",
    "        loss += torch.abs(a[0]).sum()*l1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step(lambda: loss)\n",
    "        if t%100 == 0:\n",
    "            temp_test = test_labels[torch.where(test_attn_mask == False)].detach().cpu().numpy()\n",
    "            temp_train = train_labels[train_perm][:300][torch.where(train_attn_mask[train_perm][:300] == False)].detach().cpu().numpy()\n",
    "            test_out = model(test_in, mask=test_attn_mask)[torch.where(test_attn_mask == False)].detach().cpu().numpy()\n",
    "            train_out = model(train_in[train_perm][:300], mask=train_attn_mask[train_perm][:300])[torch.where(train_attn_mask[train_perm][:300] == False)].detach().cpu().numpy()\n",
    "            train_score = 0\n",
    "            val_score = 0\n",
    "            for n in range(len(test_out)):\n",
    "                if test_out[n] >= 0.5 and temp_test[n] == 1:\n",
    "                    val_score += 1\n",
    "                elif test_out[n] <= 0.5 and temp_test[n] == 0:\n",
    "                    val_score += 1\n",
    "\n",
    "            c = 0\n",
    "            for n in range(len(train_out)):\n",
    "                if train_out[n] >= 0.5 and temp_train[n] == 1:\n",
    "                    train_score += 1\n",
    "                elif train_out[n] <= 0.5 and temp_train[n] == 0:\n",
    "                    train_score += 1\n",
    "                c += 1\n",
    "                \n",
    "            print(t, loss)\n",
    "            print(\"train f1: \", train_score/c)\n",
    "            print(\"val f1: \",val_score/len(test_out))\n",
    "            \"\"\"if val_score > max_val_f1:\n",
    "                max_val_f1 = val_score\n",
    "                best_params = model.parameters()\n",
    "            if train_score > max_train_f1:\n",
    "                max_train_f1 = val_score\n",
    "                best_params = model.parameters()\"\"\"\n",
    "        if loss.item() < current_min:\n",
    "            num_since = 0\n",
    "            current_min = loss\n",
    "            \n",
    "        elif num_since >= max_iter:\n",
    "            print(\"max iter\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            num_since += 1\n",
    "    \n",
    "    return (max_val_f1, max_train_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.enc1 = nn.TransformerEncoderLayer(d_model=len(trans_train[0][0]), nhead=9, batch_first=True, dim_feedforward=32,dropout=0.8).cuda()\n",
    "        #self.enc2 = nn.TransformerEncoderLayer(d_model=len(trans_train[0][0]), nhead=2, batch_first=True, dim_feedforward=32, dropout=0).cuda()\n",
    "        #self.enc3 = nn.TransformerEncoderLayer(d_model=len(trans_train[0][0]), nhead=4, batch_first=True, dim_feedforward=2048, dropout=0).cuda()\n",
    "        #self.enc4 = nn.TransformerEncoderLayer(d_model=len(trans_train[0][0]), nhead=4, batch_first=True, dim_feedforward=2048, dropout=0).cuda()\n",
    "        self.l1 = nn.Linear(len(trans_train[0][0]), 1).cuda()\n",
    "        #self.l2 = nn.Linear(512, 128).cuda()\n",
    "        \"\"\"self.l3 = nn.Linear(512, 128).cuda()\n",
    "        self.l4 = nn.Linear(128, 128).cuda()\n",
    "        self.l5 = nn.Linear(128, 128).cuda()\n",
    "        self.l6 = nn.Linear(128, 128).cuda()\"\"\"\n",
    "        #self.l7 = nn.Linear(128, 33).cuda()\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.enc1(x, src_key_padding_mask=mask)\n",
    "        #x = self.enc2(x, src_key_padding_mask=mask)\n",
    "        #x = self.enc3(x, src_key_padding_mask=mask)\n",
    "        #x = self.enc4(x, src_key_padding_mask=mask)\n",
    "        x = self.l1(x)\n",
    "        \"\"\"x = func.silu(x)\n",
    "\n",
    "        x = self.l2(x)\n",
    "        x = func.silu(x)\n",
    "        \n",
    "        x = self.l3(x)\n",
    "        x = func.silu(x)\n",
    "\n",
    "        skip = x\n",
    "        x = self.l4(x)\n",
    "        x = func.silu(x)\n",
    "        x = x + skip\n",
    "        skip = x\n",
    "        x = self.l5(x)\n",
    "        x = func.silu(x)\n",
    "        x = x + skip\n",
    "        skip = x\n",
    "        x = self.l6(x)\n",
    "        x = func.silu(x)\n",
    "        x = x + skip\n",
    "        x = self.l7(x)\"\"\"\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in, test_in, train_labels, test_labels, train_attn_mask, test_attn_mask = train_test_split(trans_train, trans_labels, attn_mask, train_size=0.9)\n",
    "    \n",
    "train_in = torch.tensor(train_in).float().cuda()\n",
    "test_in = torch.tensor(test_in).float().cuda()\n",
    "train_labels = torch.tensor(train_labels).float().cuda()\n",
    "test_labels = torch.tensor(test_labels).float().cuda()\n",
    "train_attn_mask = torch.tensor(train_attn_mask).bool().cuda()\n",
    "test_attn_mask = torch.tensor(test_attn_mask).bool().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdo = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9486866218692731\n",
      "val f1:  0.9343267108167771\n",
      "100 tensor(0.3700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9486866218692731\n",
      "val f1:  0.9328550404709345\n",
      "200 tensor(0.3437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.949602932193036\n",
      "val f1:  0.9332229580573952\n",
      "300 tensor(0.3144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9480757483200978\n",
      "val f1:  0.9324871228844739\n",
      "400 tensor(0.4313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9480757483200978\n",
      "val f1:  0.9335908756438558\n",
      "500 tensor(0.4184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9483811850946854\n",
      "val f1:  0.9343267108167771\n",
      "600 tensor(0.3109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9434941967012829\n",
      "val f1:  0.9337748344370861\n",
      "700 tensor(0.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9517409896151496\n",
      "val f1:  0.931383370125092\n",
      "800 tensor(0.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.950519242516799\n",
      "val f1:  0.9361662987490802\n",
      "900 tensor(0.3693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9468540012217471\n",
      "val f1:  0.9335908756438558\n",
      "1000 tensor(0.2942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9520464263897374\n",
      "val f1:  0.9352465047829286\n",
      "1100 tensor(0.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.950519242516799\n",
      "val f1:  0.9350625459896983\n",
      "1200 tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9462431276725718\n",
      "val f1:  0.9337748344370861\n",
      "1300 tensor(0.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9526572999389127\n",
      "val f1:  0.9361662987490802\n",
      "1400 tensor(0.3025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9462431276725718\n",
      "val f1:  0.9343267108167771\n",
      "1500 tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9499083689676237\n",
      "val f1:  0.9337748344370861\n",
      "1600 tensor(0.3900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9465485644471594\n",
      "val f1:  0.9345106696100074\n",
      "1700 tensor(0.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9551007941356139\n",
      "val f1:  0.9337748344370861\n",
      "1800 tensor(0.3557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9486866218692731\n",
      "val f1:  0.934878587196468\n",
      "1900 tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.950519242516799\n",
      "val f1:  0.9376379690949227\n",
      "2000 tensor(0.3989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9502138057422114\n",
      "val f1:  0.9374540103016924\n",
      "2100 tensor(0.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9486866218692731\n",
      "val f1:  0.9356144223693893\n",
      "2200 tensor(0.3766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9465485644471594\n",
      "val f1:  0.9335908756438558\n",
      "2300 tensor(0.3664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9456322541233965\n",
      "val f1:  0.9335908756438558\n",
      "2400 tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9480757483200978\n",
      "val f1:  0.9367181751287712\n",
      "2500 tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9575442883323152\n",
      "val f1:  0.9356144223693893\n",
      "2600 tensor(0.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.952351863164325\n",
      "val f1:  0.9337748344370861\n",
      "2700 tensor(0.3916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9502138057422114\n",
      "val f1:  0.9321192052980133\n",
      "2800 tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9520464263897374\n",
      "val f1:  0.9361662987490802\n",
      "2900 tensor(0.3653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9477703115455101\n",
      "val f1:  0.9299116997792495\n",
      "3000 tensor(0.3563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9520464263897374\n",
      "val f1:  0.9345106696100074\n",
      "3100 tensor(0.4417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9447159437996335\n",
      "val f1:  0.9330389992641648\n",
      "3200 tensor(0.3170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9502138057422114\n",
      "val f1:  0.9350625459896983\n",
      "3300 tensor(0.3732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9480757483200978\n",
      "val f1:  0.9339587932303164\n",
      "3400 tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.949602932193036\n",
      "val f1:  0.9311994113318617\n",
      "3500 tensor(0.3561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.953268173488088\n",
      "val f1:  0.9323031640912436\n",
      "3600 tensor(0.4201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9551007941356139\n",
      "val f1:  0.9330389992641648\n",
      "3700 tensor(0.3237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9511301160659743\n",
      "val f1:  0.9352465047829286\n",
      "3800 tensor(0.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9499083689676237\n",
      "val f1:  0.9354304635761589\n",
      "3900 tensor(0.3053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9526572999389127\n",
      "val f1:  0.9365342163355408\n",
      "4000 tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9468540012217471\n",
      "val f1:  0.9361662987490802\n",
      "4100 tensor(0.3377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9471594379963347\n",
      "val f1:  0.9337748344370861\n",
      "4200 tensor(0.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9492974954184484\n",
      "val f1:  0.9352465047829286\n",
      "4300 tensor(0.3776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9526572999389127\n",
      "val f1:  0.9361662987490802\n",
      "4400 tensor(0.3602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9465485644471594\n",
      "val f1:  0.934878587196468\n",
      "4500 tensor(0.3061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.952351863164325\n",
      "val f1:  0.9341427520235467\n",
      "4600 tensor(0.4260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9526572999389127\n",
      "val f1:  0.9346946284032377\n",
      "4700 tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9499083689676237\n",
      "val f1:  0.9352465047829286\n",
      "4800 tensor(0.2995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.950519242516799\n",
      "val f1:  0.9363502575423105\n",
      "4900 tensor(0.3756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.953268173488088\n",
      "val f1:  0.9288079470198676\n",
      "5000 tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "train f1:  0.9508246792913867\n",
      "val f1:  0.9350625459896983\n",
      "max iter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop(mdo, learning_rate=0.0001, l1=0.001, batch_size=25, max_iter=5000, train_in=train_in, test_in=test_in, train_labels=train_labels, test_labels=test_labels, train_attn_mask=train_attn_mask, test_attn_mask=test_attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_per_process_memory_fraction(1.0, device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = next_mdl(torch.tensor(train_next[:,:-1]).cuda().float()).detach().cpu().numpy()\n",
    "d = pd.DataFrame(data=preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.592755e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.441378e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.334971e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.829331e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.137788e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50116</th>\n",
       "      <td>4.750222e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50117</th>\n",
       "      <td>2.042918e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50118</th>\n",
       "      <td>3.029681e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50119</th>\n",
       "      <td>7.438381e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50120</th>\n",
       "      <td>5.272496e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50121 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0      9.592755e-01\n",
       "1      1.441378e-07\n",
       "2      2.334971e-11\n",
       "3      1.829331e-11\n",
       "4      1.137788e-04\n",
       "...             ...\n",
       "50116  4.750222e-04\n",
       "50117  2.042918e-01\n",
       "50118  3.029681e-08\n",
       "50119  7.438381e-07\n",
       "50120  5.272496e-08\n",
       "\n",
       "[50121 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv(\"next_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversion(inp):\n",
    "    out = []\n",
    "    for i in inp.flatten():\n",
    "        if i >= 0.5:\n",
    "            out.append(1)\n",
    "        else:\n",
    "            out.append(0)\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0045, -2.2230,  0.4590,  ..., -0.3259, -0.8462, -0.6578],\n",
       "        [ 0.0914, -0.2589, -0.4519,  ..., -0.2106,  0.2137, -0.6841],\n",
       "        [-2.4855,  0.7789, -1.3104,  ...,  0.8067,  1.1176,  0.0912],\n",
       "        ...,\n",
       "        [ 0.9118, -1.2789, -0.7210,  ..., -0.1166, -0.4972,  0.4478],\n",
       "        [ 0.4116,  0.8131,  1.2205,  ...,  2.2558, -1.5663,  0.0420],\n",
       "        [-0.7056,  0.4058, -0.3226,  ...,  1.6992, -0.8753,  0.9845]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_s[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_68899/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2946502797.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_68899/2946502797.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">container.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 │   # with Any as TorchScript expects a more precise type</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>139 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> = module(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 │   </span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">append</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module: Module) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">'Sequential'</span>:                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/sentence_transformers/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Transformer.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">62</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 59 │   </span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, features):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61 │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Returns token_embeddings, cls_token\"\"\"</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 62 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>trans_features = {<span style=\"color: #808000; text-decoration-color: #808000\">'input_ids'</span>: features[<span style=\"color: #808000; text-decoration-color: #808000\">'input_ids'</span>], <span style=\"color: #808000; text-decoration-color: #808000\">'attention_mask'</span>: fea <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 63 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">'token_type_ids'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> features:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 │   │   │   </span>trans_features[<span style=\"color: #808000; text-decoration-color: #808000\">'token_type_ids'</span>] = features[<span style=\"color: #808000; text-decoration-color: #808000\">'token_type_ids'</span>]           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndexError: </span>too many indices for tensor of dimension <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_68899/\u001b[0m\u001b[1;33m2946502797.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_68899/2946502797.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mcontainer.py\u001b[0m:\u001b[94m139\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# with Any as TorchScript expects a more precise type\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m139 \u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m = module(\u001b[96minput\u001b[0m)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96minput\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mappend\u001b[0m(\u001b[96mself\u001b[0m, module: Module) -> \u001b[33m'\u001b[0m\u001b[33mSequential\u001b[0m\u001b[33m'\u001b[0m:                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/sentence_transformers/models/\u001b[0m\u001b[1;33mTransformer.\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m62\u001b[0m in \u001b[92mforward\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 59 \u001b[0m\u001b[2m│   \u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, features):                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 62 \u001b[2m│   │   \u001b[0mtrans_features = {\u001b[33m'\u001b[0m\u001b[33minput_ids\u001b[0m\u001b[33m'\u001b[0m: features[\u001b[33m'\u001b[0m\u001b[33minput_ids\u001b[0m\u001b[33m'\u001b[0m], \u001b[33m'\u001b[0m\u001b[33mattention_mask\u001b[0m\u001b[33m'\u001b[0m: fea \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 63 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m'\u001b[0m\u001b[33mtoken_type_ids\u001b[0m\u001b[33m'\u001b[0m \u001b[95min\u001b[0m features:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrans_features[\u001b[33m'\u001b[0m\u001b[33mtoken_type_ids\u001b[0m\u001b[33m'\u001b[0m] = features[\u001b[33m'\u001b[0m\u001b[33mtoken_type_ids\u001b[0m\u001b[33m'\u001b[0m]           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mIndexError: \u001b[0mtoo many indices for tensor of dimension \u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model(train_s[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_next(\n",
       "  (l1): Linear(in_features=220, out_features=64, bias=True)\n",
       "  (l2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (l5): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_mdl.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38538    31]\n",
      " [  355  6184]]\n",
      "[[4184  106]\n",
      " [ 123  600]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(get_conversion(next_mdl(train_s[:,:-1]).detach().cpu().numpy()), train_s[:,-1].detach().cpu().numpy().flatten()))\n",
    "print(confusion_matrix(get_conversion(next_mdl(test_s[:,:-1]).detach().cpu().numpy()), test_s[:,-1].detach().cpu().numpy().flatten()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
