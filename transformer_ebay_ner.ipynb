{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-10-31 20:09:10.577970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 20:09:10.578429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 20:09:10.578560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as func\n",
    "from torch.nn import Linear as lin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from torch.distributions.multinomial import Multinomial\n",
    "from transformers import BertForTokenClassification\n",
    "from transformers import PreTrainedTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DistilBertTokenizer, DistilBertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train_Tagged_Titles.tsv.gz\", sep=\"\\t\", dtype=str, keep_default_na=False, na_values=[\"\"], quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(df):\n",
    "    text = []\n",
    "    for i in range(1,5001):\n",
    "        listing = df[df[\"Record Number\"] == str(i)]\n",
    "        text.append(listing[\"Token\"].values.tolist())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = None\n",
    "for i in range(len(df)):\n",
    "    if type(df[\"Tag\"][i]) == float:\n",
    "        df[\"Tag\"][i] = last\n",
    "    last = df[\"Tag\"].values[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(df, idx, t):\n",
    "    out = [-100]\n",
    "    listing = df[df[\"Record Number\"] == str(idx + 1)]\n",
    "\n",
    "    for idx, row in listing.iterrows():\n",
    "        out += (t(row[\"Token\"], padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")[\"input_ids\"].argmin().item() - 2)*[tags[row[\"Tag\"]]]\n",
    "    out += [-100]*(512 - len(out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_data = None\n",
    "for i in range(1,5001):\n",
    "    if i == 1:\n",
    "        total_data = df[df[\"Record Number\"] == str(i)]\n",
    "    else:\n",
    "        total_data.append(df[df[\"Record Number\"] == str(i)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "a = tokenizer(get_text(df), padding='max_length', max_length=512, is_split_into_words=True, truncation=True, return_tensors=\"pt\")\n",
    "labels = []\n",
    "for i in range(len(a)):\n",
    "    labels.append(get_labels(df, i, tokenizer))\n",
    "labels = torch.tensor(labels)\n",
    "a.token_type_ids = labels\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=32)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSequence(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, d):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        a = tokenizer(get_text(d), padding='max_length', max_length=512, is_split_into_words=True, truncation=True, return_tensors=\"pt\")\n",
    "        labels = []\n",
    "        for i in range(len(a)):\n",
    "            labels.append(get_labels(d, i, tokenizer))\n",
    "        labels = torch.tensor(labels)\n",
    "        for k in a.keys():\n",
    "            a[k].to(torch.int32)\n",
    "        self.encodings = a\n",
    "        self.labels = labels.to(torch.int32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).to(torch.int32)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSequence1(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, d):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        a = tokenizer(get_text(d), padding='max_length', max_length=512, is_split_into_words=True, truncation=True, return_tensors=\"pt\")\n",
    "        labels = []\n",
    "        for i in range(len(a)):\n",
    "            labels.append(get_labels(d, i, tokenizer))\n",
    "        labels = torch.tensor(labels)\n",
    "        for k in a.keys():\n",
    "            a[k].to(torch.int32)\n",
    "        self.encodings = a\n",
    "        self.labels = labels.to(torch.int32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).to(torch.int32)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", per_device_eval_batch_size=100, num_train_epochs=100,disable_tqdm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/henry/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/henry/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/henry/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/henry/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/henry/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/henry/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "  0%|          | 0/3 [16:44<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "d1 = DataSequence(df)\n",
    "d2 = DataSequence(df)\n",
    "trainer = Trainer(model=model,args=training_args,train_dataset=d1,eval_dataset=d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,args=training_args,train_dataset=d1,eval_dataset=d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 100\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\n",
      "\u001b[A/tmp/ipykernel_15659/4138526111.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_15659/4138526111.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx]).to(torch.int32).type(torch.LongTensor)\n",
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:33<00:00,  2.88it/s]  \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.000525879324413836, 'eval_runtime': 0.0832, 'eval_samples_per_second': 36.071, 'eval_steps_per_second': 12.024, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:33<00:00,  2.88it/s]  \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.000518342771101743, 'eval_runtime': 0.0809, 'eval_samples_per_second': 37.071, 'eval_steps_per_second': 12.357, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:34<00:00,  2.88it/s]  \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0005098597030155361, 'eval_runtime': 0.0836, 'eval_samples_per_second': 35.881, 'eval_steps_per_second': 11.96, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:34<00:00,  2.88it/s]  \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0004941302468068898, 'eval_runtime': 0.0842, 'eval_samples_per_second': 35.633, 'eval_steps_per_second': 11.878, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:34<00:00,  2.88it/s]  \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0004817330336663872, 'eval_runtime': 0.0818, 'eval_samples_per_second': 36.692, 'eval_steps_per_second': 12.231, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:35<00:00,  2.88it/s]  \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0004703559970948845, 'eval_runtime': 0.0832, 'eval_samples_per_second': 36.04, 'eval_steps_per_second': 12.013, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:35<00:00,  2.88it/s]  \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00045915646478533745, 'eval_runtime': 0.0835, 'eval_samples_per_second': 35.946, 'eval_steps_per_second': 11.982, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:35<00:00,  2.88it/s]  \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0004478256742004305, 'eval_runtime': 0.0826, 'eval_samples_per_second': 36.32, 'eval_steps_per_second': 12.107, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:36<00:00,  2.88it/s]  \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00043714127968996763, 'eval_runtime': 0.0839, 'eval_samples_per_second': 35.776, 'eval_steps_per_second': 11.925, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:36<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0004271611396688968, 'eval_runtime': 0.0833, 'eval_samples_per_second': 36.017, 'eval_steps_per_second': 12.006, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:37<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0004174447094555944, 'eval_runtime': 0.0848, 'eval_samples_per_second': 35.391, 'eval_steps_per_second': 11.797, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:37<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0004079424834344536, 'eval_runtime': 0.0831, 'eval_samples_per_second': 36.087, 'eval_steps_per_second': 12.029, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:37<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003987755917478353, 'eval_runtime': 0.0842, 'eval_samples_per_second': 35.634, 'eval_steps_per_second': 11.878, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:38<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003892954846378416, 'eval_runtime': 0.0845, 'eval_samples_per_second': 35.488, 'eval_steps_per_second': 11.829, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:38<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00037975082523189485, 'eval_runtime': 0.0843, 'eval_samples_per_second': 35.605, 'eval_steps_per_second': 11.868, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:39<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003703644033521414, 'eval_runtime': 0.0841, 'eval_samples_per_second': 35.678, 'eval_steps_per_second': 11.893, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:39<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003615125606302172, 'eval_runtime': 0.0857, 'eval_samples_per_second': 35.013, 'eval_steps_per_second': 11.671, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:39<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00035295667476020753, 'eval_runtime': 0.0829, 'eval_samples_per_second': 36.174, 'eval_steps_per_second': 12.058, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:40<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003446356568019837, 'eval_runtime': 0.085, 'eval_samples_per_second': 35.306, 'eval_steps_per_second': 11.769, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:40<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00033674013684503734, 'eval_runtime': 0.0849, 'eval_samples_per_second': 35.355, 'eval_steps_per_second': 11.785, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:41<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003292751789558679, 'eval_runtime': 0.0841, 'eval_samples_per_second': 35.66, 'eval_steps_per_second': 11.887, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:41<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003223771636839956, 'eval_runtime': 0.0861, 'eval_samples_per_second': 34.854, 'eval_steps_per_second': 11.618, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:41<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00031602365197613835, 'eval_runtime': 0.084, 'eval_samples_per_second': 35.718, 'eval_steps_per_second': 11.906, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:42<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0003100855683442205, 'eval_runtime': 0.0827, 'eval_samples_per_second': 36.26, 'eval_steps_per_second': 12.087, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:42<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00030455939122475684, 'eval_runtime': 0.0825, 'eval_samples_per_second': 36.345, 'eval_steps_per_second': 12.115, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:43<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00029939072555862367, 'eval_runtime': 0.0837, 'eval_samples_per_second': 35.847, 'eval_steps_per_second': 11.949, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:43<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00029447232373058796, 'eval_runtime': 0.0836, 'eval_samples_per_second': 35.891, 'eval_steps_per_second': 11.964, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:43<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00028982284129597247, 'eval_runtime': 0.0818, 'eval_samples_per_second': 36.691, 'eval_steps_per_second': 12.23, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:44<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00028537260368466377, 'eval_runtime': 0.0844, 'eval_samples_per_second': 35.564, 'eval_steps_per_second': 11.855, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:44<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00028104489319957793, 'eval_runtime': 0.0819, 'eval_samples_per_second': 36.613, 'eval_steps_per_second': 12.204, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:44<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002766865654848516, 'eval_runtime': 0.0829, 'eval_samples_per_second': 36.187, 'eval_steps_per_second': 12.062, 'epoch': 31.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:45<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002723980287555605, 'eval_runtime': 0.0852, 'eval_samples_per_second': 35.222, 'eval_steps_per_second': 11.741, 'epoch': 32.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:45<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00026819115737453103, 'eval_runtime': 0.0843, 'eval_samples_per_second': 35.588, 'eval_steps_per_second': 11.863, 'epoch': 33.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:46<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00026404898380860686, 'eval_runtime': 0.0838, 'eval_samples_per_second': 35.807, 'eval_steps_per_second': 11.936, 'epoch': 34.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:46<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002599953149911016, 'eval_runtime': 0.0829, 'eval_samples_per_second': 36.21, 'eval_steps_per_second': 12.07, 'epoch': 35.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:46<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00025609659496694803, 'eval_runtime': 0.0839, 'eval_samples_per_second': 35.765, 'eval_steps_per_second': 11.922, 'epoch': 36.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:47<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002524616720620543, 'eval_runtime': 0.0846, 'eval_samples_per_second': 35.455, 'eval_steps_per_second': 11.818, 'epoch': 37.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:47<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002489884791430086, 'eval_runtime': 0.0846, 'eval_samples_per_second': 35.462, 'eval_steps_per_second': 11.821, 'epoch': 38.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:48<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00024580478202551603, 'eval_runtime': 0.0828, 'eval_samples_per_second': 36.216, 'eval_steps_per_second': 12.072, 'epoch': 39.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:48<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002427333383820951, 'eval_runtime': 0.0845, 'eval_samples_per_second': 35.501, 'eval_steps_per_second': 11.834, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:48<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00023977096134331077, 'eval_runtime': 0.0835, 'eval_samples_per_second': 35.945, 'eval_steps_per_second': 11.982, 'epoch': 41.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:49<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00023682205937802792, 'eval_runtime': 0.0847, 'eval_samples_per_second': 35.422, 'eval_steps_per_second': 11.807, 'epoch': 42.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:49<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00023390045680571347, 'eval_runtime': 0.0837, 'eval_samples_per_second': 35.835, 'eval_steps_per_second': 11.945, 'epoch': 43.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:50<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00023104867432266474, 'eval_runtime': 0.087, 'eval_samples_per_second': 34.479, 'eval_steps_per_second': 11.493, 'epoch': 44.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:50<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00022835687559563667, 'eval_runtime': 0.0848, 'eval_samples_per_second': 35.357, 'eval_steps_per_second': 11.786, 'epoch': 45.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:50<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00022581832308787853, 'eval_runtime': 0.0845, 'eval_samples_per_second': 35.517, 'eval_steps_per_second': 11.839, 'epoch': 46.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:51<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002234687708551064, 'eval_runtime': 0.0856, 'eval_samples_per_second': 35.06, 'eval_steps_per_second': 11.687, 'epoch': 47.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:51<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002212298713857308, 'eval_runtime': 0.0826, 'eval_samples_per_second': 36.303, 'eval_steps_per_second': 12.101, 'epoch': 48.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:51<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00021908800408709794, 'eval_runtime': 0.0852, 'eval_samples_per_second': 35.21, 'eval_steps_per_second': 11.737, 'epoch': 49.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:52<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00021703804668504745, 'eval_runtime': 0.0853, 'eval_samples_per_second': 35.175, 'eval_steps_per_second': 11.725, 'epoch': 50.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:52<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00021500856382772326, 'eval_runtime': 0.0847, 'eval_samples_per_second': 35.411, 'eval_steps_per_second': 11.804, 'epoch': 51.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:53<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00021306420967448503, 'eval_runtime': 0.0856, 'eval_samples_per_second': 35.063, 'eval_steps_per_second': 11.688, 'epoch': 52.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:53<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00021120662859175354, 'eval_runtime': 0.085, 'eval_samples_per_second': 35.297, 'eval_steps_per_second': 11.766, 'epoch': 53.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:53<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0002093848743243143, 'eval_runtime': 0.0818, 'eval_samples_per_second': 36.691, 'eval_steps_per_second': 12.23, 'epoch': 54.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:54<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00020764135115314275, 'eval_runtime': 0.0863, 'eval_samples_per_second': 34.776, 'eval_steps_per_second': 11.592, 'epoch': 55.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:54<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00020590471103787422, 'eval_runtime': 0.0847, 'eval_samples_per_second': 35.436, 'eval_steps_per_second': 11.812, 'epoch': 56.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:55<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00020425149705260992, 'eval_runtime': 0.0837, 'eval_samples_per_second': 35.823, 'eval_steps_per_second': 11.941, 'epoch': 57.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:55<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00020264585327822715, 'eval_runtime': 0.0882, 'eval_samples_per_second': 34.009, 'eval_steps_per_second': 11.336, 'epoch': 58.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:55<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00020110160403419286, 'eval_runtime': 0.0873, 'eval_samples_per_second': 34.355, 'eval_steps_per_second': 11.452, 'epoch': 59.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:56<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001995913771679625, 'eval_runtime': 0.0835, 'eval_samples_per_second': 35.912, 'eval_steps_per_second': 11.971, 'epoch': 60.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:56<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00019817135762423277, 'eval_runtime': 0.086, 'eval_samples_per_second': 34.897, 'eval_steps_per_second': 11.632, 'epoch': 61.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:57<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00019682972924783826, 'eval_runtime': 0.0847, 'eval_samples_per_second': 35.417, 'eval_steps_per_second': 11.806, 'epoch': 62.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:57<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00019556807819753885, 'eval_runtime': 0.0848, 'eval_samples_per_second': 35.391, 'eval_steps_per_second': 11.797, 'epoch': 63.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:57<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00019434381101746112, 'eval_runtime': 0.0877, 'eval_samples_per_second': 34.218, 'eval_steps_per_second': 11.406, 'epoch': 64.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:58<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001931690494529903, 'eval_runtime': 0.0848, 'eval_samples_per_second': 35.364, 'eval_steps_per_second': 11.788, 'epoch': 65.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:58<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00019204190175514668, 'eval_runtime': 0.0875, 'eval_samples_per_second': 34.284, 'eval_steps_per_second': 11.428, 'epoch': 66.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:59<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00019098963821306825, 'eval_runtime': 0.0849, 'eval_samples_per_second': 35.316, 'eval_steps_per_second': 11.772, 'epoch': 67.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:59<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00018994421407114714, 'eval_runtime': 0.0824, 'eval_samples_per_second': 36.412, 'eval_steps_per_second': 12.137, 'epoch': 68.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [27:59<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00018895159882958978, 'eval_runtime': 0.0874, 'eval_samples_per_second': 34.34, 'eval_steps_per_second': 11.447, 'epoch': 69.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:00<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00018792826449498534, 'eval_runtime': 0.0846, 'eval_samples_per_second': 35.445, 'eval_steps_per_second': 11.815, 'epoch': 70.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:00<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00018696457846090198, 'eval_runtime': 0.0868, 'eval_samples_per_second': 34.55, 'eval_steps_per_second': 11.517, 'epoch': 71.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:00<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001860229967860505, 'eval_runtime': 0.0866, 'eval_samples_per_second': 34.624, 'eval_steps_per_second': 11.541, 'epoch': 72.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:01<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00018512742826715112, 'eval_runtime': 0.0826, 'eval_samples_per_second': 36.299, 'eval_steps_per_second': 12.1, 'epoch': 73.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:01<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001842539495555684, 'eval_runtime': 0.0856, 'eval_samples_per_second': 35.057, 'eval_steps_per_second': 11.686, 'epoch': 74.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:02<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00018343325064051896, 'eval_runtime': 0.0857, 'eval_samples_per_second': 35.023, 'eval_steps_per_second': 11.674, 'epoch': 75.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:02<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001826772786444053, 'eval_runtime': 0.0848, 'eval_samples_per_second': 35.382, 'eval_steps_per_second': 11.794, 'epoch': 76.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:02<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00018194173753727227, 'eval_runtime': 0.085, 'eval_samples_per_second': 35.301, 'eval_steps_per_second': 11.767, 'epoch': 77.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:03<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001812010887078941, 'eval_runtime': 0.0857, 'eval_samples_per_second': 35.011, 'eval_steps_per_second': 11.67, 'epoch': 78.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:03<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00018050811195280403, 'eval_runtime': 0.0852, 'eval_samples_per_second': 35.206, 'eval_steps_per_second': 11.735, 'epoch': 79.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:04<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017986109014600515, 'eval_runtime': 0.0865, 'eval_samples_per_second': 34.691, 'eval_steps_per_second': 11.564, 'epoch': 80.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:04<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017924128042068332, 'eval_runtime': 0.0864, 'eval_samples_per_second': 34.711, 'eval_steps_per_second': 11.57, 'epoch': 81.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:04<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017866409325506538, 'eval_runtime': 0.0874, 'eval_samples_per_second': 34.315, 'eval_steps_per_second': 11.438, 'epoch': 82.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:05<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001781039172783494, 'eval_runtime': 0.0857, 'eval_samples_per_second': 35.017, 'eval_steps_per_second': 11.672, 'epoch': 83.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:05<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001775795390130952, 'eval_runtime': 0.0842, 'eval_samples_per_second': 35.629, 'eval_steps_per_second': 11.876, 'epoch': 84.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:06<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017709766689222306, 'eval_runtime': 0.0854, 'eval_samples_per_second': 35.149, 'eval_steps_per_second': 11.716, 'epoch': 85.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:06<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.000176636254764162, 'eval_runtime': 0.0857, 'eval_samples_per_second': 35.004, 'eval_steps_per_second': 11.668, 'epoch': 86.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:06<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001761935418471694, 'eval_runtime': 0.088, 'eval_samples_per_second': 34.076, 'eval_steps_per_second': 11.359, 'epoch': 87.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:07<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017577125981915742, 'eval_runtime': 0.0845, 'eval_samples_per_second': 35.507, 'eval_steps_per_second': 11.836, 'epoch': 88.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:07<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017542392015457153, 'eval_runtime': 0.0848, 'eval_samples_per_second': 35.395, 'eval_steps_per_second': 11.798, 'epoch': 89.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:08<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017508167366031557, 'eval_runtime': 0.0854, 'eval_samples_per_second': 35.128, 'eval_steps_per_second': 11.709, 'epoch': 90.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:08<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017477350775152445, 'eval_runtime': 0.0853, 'eval_samples_per_second': 35.178, 'eval_steps_per_second': 11.726, 'epoch': 91.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:08<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017450789164286107, 'eval_runtime': 0.086, 'eval_samples_per_second': 34.903, 'eval_steps_per_second': 11.634, 'epoch': 92.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:09<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017424736870452762, 'eval_runtime': 0.0863, 'eval_samples_per_second': 34.749, 'eval_steps_per_second': 11.583, 'epoch': 93.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:09<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017404479149263352, 'eval_runtime': 0.0857, 'eval_samples_per_second': 35.0, 'eval_steps_per_second': 11.667, 'epoch': 94.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:10<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017387796833645552, 'eval_runtime': 0.0854, 'eval_samples_per_second': 35.149, 'eval_steps_per_second': 11.716, 'epoch': 95.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:10<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017373320588376373, 'eval_runtime': 0.085, 'eval_samples_per_second': 35.296, 'eval_steps_per_second': 11.765, 'epoch': 96.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:10<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0001736157137202099, 'eval_runtime': 0.0873, 'eval_samples_per_second': 34.375, 'eval_steps_per_second': 11.458, 'epoch': 97.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:11<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017351524729747325, 'eval_runtime': 0.0859, 'eval_samples_per_second': 34.92, 'eval_steps_per_second': 11.64, 'epoch': 98.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:11<00:00,  2.88it/s]   \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017345225205644965, 'eval_runtime': 0.0863, 'eval_samples_per_second': 34.764, 'eval_steps_per_second': 11.588, 'epoch': 99.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 3\n",
      "  Batch size = 100\n",
      "\n",
      "\n",
      "                                             \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                            \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:11<00:00,  2.88it/s]    \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "                                             \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 1/3 [28:11<00:00,  2.88it/s]    \n",
      "100%|██████████| 100/100 [00:39<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00017342840146739036, 'eval_runtime': 0.0874, 'eval_samples_per_second': 34.343, 'eval_steps_per_second': 11.448, 'epoch': 100.0}\n",
      "{'train_runtime': 39.1386, 'train_samples_per_second': 7.665, 'train_steps_per_second': 2.555, 'train_loss': 0.00043888162821531296, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.00043888162821531296, metrics={'train_runtime': 39.1386, 'train_samples_per_second': 7.665, 'train_steps_per_second': 2.555, 'train_loss': 0.00043888162821531296, 'epoch': 100.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">47</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 244 │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 245 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, item: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 246 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 247 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.data[item]                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 248 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 249 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 250 </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'label_ids'</span>\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_3567/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2221106546.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_3567/2221106546.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">49</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 246 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 247 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.data[item]                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 248 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 249 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 250 │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 251 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getstate__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 252 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> {<span style=\"color: #808000; text-decoration-color: #808000\">\"data\"</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.data, <span style=\"color: #808000; text-decoration-color: #808000\">\"encodings\"</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._encodings}                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_utils_base.py\u001b[0m:\u001b[94m2\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m47\u001b[0m in \u001b[92m__getattr__\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 244 \u001b[0m\u001b[2m│   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 245 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__getattr__\u001b[0m(\u001b[96mself\u001b[0m, item: \u001b[96mstr\u001b[0m):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 246 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 247 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.data[item]                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 248 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyError\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 249 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 250 \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'label_ids'\u001b[0m\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_3567/\u001b[0m\u001b[1;33m2221106546.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_3567/2221106546.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_utils_base.py\u001b[0m:\u001b[94m2\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m49\u001b[0m in \u001b[92m__getattr__\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 246 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 247 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.data[item]                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 248 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyError\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 249 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 250 \u001b[0m\u001b[2m│   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 251 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__getstate__\u001b[0m(\u001b[96mself\u001b[0m):                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 252 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m {\u001b[33m\"\u001b[0m\u001b[33mdata\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mself\u001b[0m.data, \u001b[33m\"\u001b[0m\u001b[33mencodings\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mself\u001b[0m._encodings}                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSequence(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, d):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        a = tokenizer(get_text(d), padding='max_length', max_length=512, is_split_into_words=True, truncation=True, return_tensors=\"pt\")\n",
    "        labels = []\n",
    "        for i in range(len(a)):\n",
    "            labels.append(get_labels(d, i, tokenizer))\n",
    "        labels = torch.tensor(labels)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.texts = a\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_data(self, idx):\n",
    "\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "\n",
    "        return torch.LongTensor(self.labels[idx])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_data = self.get_batch_data(idx)\n",
    "        batch_labels = self.get_batch_labels(idx)\n",
    "        return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {}\n",
    "cnt = 0\n",
    "for i in set(df[\"Tag\"].values.tolist()):\n",
    "    cnt += 1\n",
    "    tags[i] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(BertModel, self).__init__()\n",
    "\n",
    "        self.bert = DistilBertForTokenClassification.from_pretrained('distilbert-base-uncased', num_labels=len(tags))\n",
    "\n",
    "    def forward(self, input_id, mask, label):\n",
    "\n",
    "        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2204227447509766"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/henry/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/henry/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/henry/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/henry/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/henry/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/henry/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/henry/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/henry/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/henry/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/henry/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/henry/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/henry/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/henry/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/henry/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_3567/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">747853408.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">78</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 78&gt;</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_3567/747853408.py'</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_3567/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">747853408.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">27</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_loop</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_3567/747853408.py'</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/tqdm/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">std.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1195</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   </span>time = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._time                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1194 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1195 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> obj <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> iterable:                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> obj                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 │   │   │   │   # Update and possibly print the progressbar.</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1198 │   │   │   │   # Note: does not call self.update(1) for speed optimisation.</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">681</span> in     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 678 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 679 │   │   │   │   # TODO(https://github.com/pytorch/pytorch/issues/76750)</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 680 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 681 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 682 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 683 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 684 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1376</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1373 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._task_info[idx] += (data,)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1374 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1375 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">del</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._task_info[idx]                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1376 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._process_data(data)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1377 │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1378 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_try_put_index</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1379 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._tasks_outstanding &lt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._prefetch_factor * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_workers <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1402</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_process_data</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1399 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._rcvd_idx += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1400 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._try_put_index()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1401 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(data, ExceptionWrapper):                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1402 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data.reraise()                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1403 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1404 │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1405 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_mark_worker_as_unavailable</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, worker_id, shutdown=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/henry/.local/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">461</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reraise</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">458 │   │   │   # If the exception takes multiple arguments, don't try to</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">459 │   │   │   # instantiate since we don't know how to</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">460 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(msg) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">None</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>461 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> exception                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">462 </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">463 </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">464 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_available_device_type</span>():                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>Caught TypeError in DataLoader worker process <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.\n",
       "Original Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">302</span>, in _worker_loop\n",
       "    data = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fetcher.fetch</span><span style=\"font-weight: bold\">(</span>index<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">52</span>, in fetch\n",
       "    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.collate_fn</span><span style=\"font-weight: bold\">(</span>data<span style=\"font-weight: bold\">)</span>\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">175</span>, in default_collate\n",
       "    return <span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">default_collate</span><span style=\"font-weight: bold\">(</span>samples<span style=\"font-weight: bold\">)</span> for samples in transposed<span style=\"font-weight: bold\">]</span>  # Backwards compatibility.\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">175</span>, in <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">listcomp</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "    return <span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">default_collate</span><span style=\"font-weight: bold\">(</span>samples<span style=\"font-weight: bold\">)</span> for samples in transposed<span style=\"font-weight: bold\">]</span>  # Backwards compatibility.\n",
       "  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"</span>, \n",
       "line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">183</span>, in default_collate\n",
       "    raise <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TypeError</span><span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">default_collate_err_msg_format.format</span><span style=\"font-weight: bold\">(</span>elem_type<span style=\"font-weight: bold\">))</span>\n",
       "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or \n",
       "lists; found <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'tokenizers.Encoding'</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_3567/\u001b[0m\u001b[1;33m747853408.py\u001b[0m:\u001b[94m78\u001b[0m in \u001b[92m<cell line: 78>\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_3567/747853408.py'\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_3567/\u001b[0m\u001b[1;33m747853408.py\u001b[0m:\u001b[94m27\u001b[0m in \u001b[92mtrain_loop\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_3567/747853408.py'\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/tqdm/\u001b[0m\u001b[1;33mstd.py\u001b[0m:\u001b[94m1195\u001b[0m in \u001b[92m__iter__\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0mtime = \u001b[96mself\u001b[0m._time                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1194 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1195 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m obj \u001b[95min\u001b[0m iterable:                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94myield\u001b[0m obj                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Update and possibly print the progressbar.\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1198 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Note: does not call self.update(1) for speed optimisation.\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m681\u001b[0m in     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__next__\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 678 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 679 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 680 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._reset()  \u001b[2m# type: ignore[call-arg]\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 681 \u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 682 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 683 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 684 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m1376\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_next_data\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1373 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._task_info[idx] += (data,)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1374 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1375 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mdel\u001b[0m \u001b[96mself\u001b[0m._task_info[idx]                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1376 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._process_data(data)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1377 \u001b[0m\u001b[2m│   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1378 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_try_put_index\u001b[0m(\u001b[96mself\u001b[0m):                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1379 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m._tasks_outstanding < \u001b[96mself\u001b[0m._prefetch_factor * \u001b[96mself\u001b[0m._num_workers \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m1402\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_process_data\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1399 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._rcvd_idx += \u001b[94m1\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1400 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._try_put_index()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1401 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(data, ExceptionWrapper):                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1402 \u001b[2m│   │   │   \u001b[0mdata.reraise()                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1403 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1404 \u001b[0m\u001b[2m│   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1405 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_mark_worker_as_unavailable\u001b[0m(\u001b[96mself\u001b[0m, worker_id, shutdown=\u001b[94mFalse\u001b[0m):              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/henry/.local/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33m_utils.py\u001b[0m:\u001b[94m461\u001b[0m in \u001b[92mreraise\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m458 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# If the exception takes multiple arguments, don't try to\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m459 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# instantiate since we don't know how to\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m460 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(msg) \u001b[94mfrom\u001b[0m \u001b[96mNone\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m461 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m exception                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m462 \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m463 \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m464 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_available_device_type\u001b[0m():                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0mCaught TypeError in DataLoader worker process \u001b[1;36m0\u001b[0m.\n",
       "Original Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n",
       "  File \u001b[32m\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\"\u001b[0m, \n",
       "line \u001b[1;36m302\u001b[0m, in _worker_loop\n",
       "    data = \u001b[1;35mfetcher.fetch\u001b[0m\u001b[1m(\u001b[0mindex\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\"\u001b[0m, \n",
       "line \u001b[1;36m52\u001b[0m, in fetch\n",
       "    return \u001b[1;35mself.collate_fn\u001b[0m\u001b[1m(\u001b[0mdata\u001b[1m)\u001b[0m\n",
       "  File \u001b[32m\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"\u001b[0m, \n",
       "line \u001b[1;36m175\u001b[0m, in default_collate\n",
       "    return \u001b[1m[\u001b[0m\u001b[1;35mdefault_collate\u001b[0m\u001b[1m(\u001b[0msamples\u001b[1m)\u001b[0m for samples in transposed\u001b[1m]\u001b[0m  # Backwards compatibility.\n",
       "  File \u001b[32m\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"\u001b[0m, \n",
       "line \u001b[1;36m175\u001b[0m, in \u001b[1m<\u001b[0m\u001b[1;95mlistcomp\u001b[0m\u001b[1m>\u001b[0m\n",
       "    return \u001b[1m[\u001b[0m\u001b[1;35mdefault_collate\u001b[0m\u001b[1m(\u001b[0msamples\u001b[1m)\u001b[0m for samples in transposed\u001b[1m]\u001b[0m  # Backwards compatibility.\n",
       "  File \u001b[32m\"/home/henry/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\"\u001b[0m, \n",
       "line \u001b[1;36m183\u001b[0m, in default_collate\n",
       "    raise \u001b[1;35mTypeError\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mdefault_collate_err_msg_format.format\u001b[0m\u001b[1m(\u001b[0melem_type\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or \n",
       "lists; found \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'tokenizers.Encoding'\u001b[0m\u001b[1m>\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_loop(model, df):\n",
    "    df_train, df_val = train_test_split(df, train_size=0.8)\n",
    "    train_dataset = DataSequence(df_train)\n",
    "    val_dataset = DataSequence(df_val)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=1, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, num_workers=1, batch_size=BATCH_SIZE)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    optimizer = torch.optim.Adam([[v for v in model.parameters()][-1]], lr=LEARNING_RATE)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    best_acc = 0\n",
    "    best_loss = 1000\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for train_data, train_label in tqdm(train_dataloader):\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_data['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = train_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss, logits = model(input_id, mask, train_label)\n",
    "\n",
    "            for i in range(logits.shape[0]):\n",
    "\n",
    "              logits_clean = logits[i][train_label[i] != -100]\n",
    "              label_clean = train_label[i][train_label[i] != -100]\n",
    "\n",
    "              predictions = logits_clean.argmax(dim=1)\n",
    "              acc = (predictions == label_clean).float().mean()\n",
    "              total_acc_train += acc\n",
    "              total_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        for val_data, val_label in val_dataloader:\n",
    "\n",
    "            val_label = val_label.to(device)\n",
    "            mask = val_data['attention_mask'].squeeze(1).to(device)\n",
    "            input_id = val_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            loss, logits = model(input_id, mask, val_label)\n",
    "\n",
    "            for i in range(logits.shape[0]):\n",
    "\n",
    "              logits_clean = logits[i][val_label[i] != -100]\n",
    "              label_clean = val_label[i][val_label[i] != -100]\n",
    "\n",
    "              predictions = logits_clean.argmax(dim=1)\n",
    "              acc = (predictions == label_clean).float().mean()\n",
    "              total_acc_val += acc\n",
    "              total_loss_val += loss.item()\n",
    "\n",
    "        print(f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / len(df_train): .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / len(df_val): .3f}')\n",
    "torch.cuda.empty_cache()\n",
    "LEARNING_RATE = 0.005\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 2\n",
    "model = BertModel()\n",
    "train_loop(model,total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
